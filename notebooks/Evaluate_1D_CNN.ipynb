{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bd0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#sys.path.append(\"/workspace\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from src.data.general_processor import Utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pickle\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import pathlib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from src.models.model_architectures.model_1DCNN import HopefullNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6cc58",
   "metadata": {},
   "source": [
    "## Get test data 4+1 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3139fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\annag\\\\OneDrive - Danmarks Tekniske Universitet\\\\Semester_04\\\\Special_Course_BCI\\\\03_code\\\\BCI_stroke_rehab\\\\models/1D_CNN/original_roi_d/'\n"
     ]
    }
   ],
   "source": [
    "root_path = pathlib.Path().resolve().parents[0]\n",
    "\n",
    "data_path = \"data/processed/physionet/4+1_classes/paper_channel_pair_d/\"\n",
    "modelname = \"original_roi_d/\"\n",
    "\n",
    "## Device settings\n",
    "tf.autograph.set_verbosity(0)\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.experimental.list_physical_devices('CPU')\n",
    "print(physical_devices)\n",
    "#config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "#Params\n",
    "source_path = os.path.join(root_path, data_path)\n",
    "save_path = os.path.join(root_path, \"models/1D_CNN/\", modelname)\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "# Load data\n",
    "channels = Utils.combinations[\"d\"] #[[\"C5\", \"C6\"], [\"C3\", \"C4\"], [\"C1\", \"C2\"]]\n",
    "\n",
    "exclude =  [38, 88, 89, 92, 100, 104]\n",
    "subjects = [n for n in np.arange(1,110) if n not in exclude]\n",
    "\n",
    "#Load data\n",
    "x, y = Utils.load(channels, subjects, base_path=source_path)\n",
    "\n",
    "#Transform y to one-hot-encoding\n",
    "y_one_hot  = Utils.to_one_hot(y, by_sub=False)\n",
    "\n",
    "#Reshape for scaling\n",
    "reshaped_x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "\n",
    "#Grab a test set before SMOTE\n",
    "x_train_raw, x_valid_test_raw, y_train_raw, y_valid_test_raw = train_test_split(reshaped_x,\n",
    "                                                                            y_one_hot,\n",
    "                                                                            stratify=y_one_hot,\n",
    "                                                                            test_size=0.20,\n",
    "                                                                            random_state=42)\n",
    "\n",
    "#Scale indipendently train/test\n",
    "#x_train_scaled_raw = minmax_scale(x_train_raw, axis=1)\n",
    "x_test_valid_scaled_raw = minmax_scale(x_valid_test_raw, axis=1)\n",
    "\n",
    "#Create Validation/test\n",
    "x_valid_raw, x_test_raw, y_valid, y_test = train_test_split(x_test_valid_scaled_raw,\n",
    "                                                    y_valid_test_raw,\n",
    "                                                    stratify=y_valid_test_raw,\n",
    "                                                    test_size=0.50,\n",
    "                                                    random_state=42)\n",
    "\n",
    "#x_valid = x_valid_raw.reshape(x_valid_raw.shape[0], int(x_valid_raw.shape[1]/2),2).astype(np.float64)\n",
    "x_test = x_test_raw.reshape(x_test_raw.shape[0], int(x_test_raw.shape[1]/2),2).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdc81d",
   "metadata": {},
   "source": [
    "## Get test data 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758bffa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\annag\\\\OneDrive - Danmarks Tekniske Universitet\\\\Semester_04\\\\Special_Course_BCI\\\\03_code\\\\BCI_stroke_rehab\\\\models/1D_CNN/ours_3_pairs/2023-03-31_00-13-36/'\n"
     ]
    }
   ],
   "source": [
    "root_path = pathlib.Path().resolve().parents[0]\n",
    "data_path = \"data/processed/physionet/2_classes/ours_3_pairs/\"\n",
    "modelname = \"ours_3_pairs/2023-03-31_00-13-36/\"\n",
    "\n",
    "## Device settings\n",
    "tf.autograph.set_verbosity(0)\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "physical_devices = tf.config.experimental.list_physical_devices('CPU')\n",
    "print(physical_devices)\n",
    "#config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "#Params\n",
    "source_path = os.path.join(root_path, data_path)\n",
    "save_path = os.path.join(root_path, \"models/1D_CNN/\", modelname)\n",
    "\n",
    "try:\n",
    "    os.mkdir(save_path)\n",
    "except OSError as error:\n",
    "    print(error)  \n",
    "\n",
    "# Load data\n",
    "channels = [[\"C3\",\"C4\"],[\"F3\",\"F4\"],[\"P3\",\"P4\"]]\n",
    "\n",
    "exclude =  [38, 88, 89, 92, 100, 104]\n",
    "subjects = [n for n in np.arange(1,110) if n not in exclude]\n",
    "\n",
    "#Load data\n",
    "x, y = Utils.load(channels, subjects, base_path=source_path)\n",
    "\n",
    "# #Transform y to one-hot-encoding\n",
    "# y_one_hot  = Utils.to_one_hot(y, by_sub=False)\n",
    "y_one_hot = y\n",
    "\n",
    "#Reshape for scaling\n",
    "reshaped_x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "\n",
    "#Grab a test set before SMOTE\n",
    "x_train_raw, x_valid_test_raw, y_train_raw, y_valid_test_raw = train_test_split(reshaped_x,\n",
    "                                                                            y_one_hot,\n",
    "                                                                            stratify=y_one_hot,\n",
    "                                                                            test_size=0.20,\n",
    "                                                                            random_state=42)\n",
    "#Scale indipendently train/test\n",
    "#x_train_scaled_raw = minmax_scale(x_train_raw, axis=1)\n",
    "x_test_valid_scaled_raw = minmax_scale(x_valid_test_raw, axis=1)\n",
    "\n",
    "#Create Validation/test\n",
    "x_valid_raw, x_test_raw, y_valid, y_test = train_test_split(x_test_valid_scaled_raw,\n",
    "                                                    y_valid_test_raw,\n",
    "                                                    stratify=y_valid_test_raw,\n",
    "                                                    test_size=0.50,\n",
    "                                                    random_state=42)\n",
    "\n",
    "#x_valid = x_valid_raw.reshape(x_valid_raw.shape[0], int(x_valid_raw.shape[1]/2),2).astype(np.float64)\n",
    "x_test = x_test_raw.reshape(x_test_raw.shape[0], int(x_test_raw.shape[1]/2),2).astype(np.float64)\n",
    "\n",
    "y_test_01 = []\n",
    "for y_label in y_test:\n",
    "    if y_label == 'L':\n",
    "        y_test_01.append(0)\n",
    "    elif y_label == 'R':\n",
    "        y_test_01.append(1)\n",
    "    else:\n",
    "        print(\"Test Labels are different than L or R...\")\n",
    "\n",
    "y_test = np.array(y_test_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab0759",
   "metadata": {},
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9abed257",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/annag/OneDrive - Danmarks Tekniske Universitet/Semester_04/Special_Course_BCI/03_code/BCI_stroke_rehab/models/1D_CNN/ours_3_pairs/2023-03-31_00-13-36/bestModel.h5\"\n",
    "two_class = True\n",
    "\n",
    "if two_class:\n",
    "    input_shape = (None, 500, 2)\n",
    "    loss = tf.keras.losses.binary_crossentropy\n",
    "else:\n",
    "    input_shape = (None, 640, 2)\n",
    "    loss = tf.keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21410eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (500, 2)\n",
      "Predicting 2 classes.\n",
      "Input shape: (None, 500, 2)\n",
      "Output shape: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "model = HopefullNet(inp_shape = (input_shape[1],input_shape[2]), two_class=two_class)\n",
    "model.build(input_shape)\n",
    "model.load_weights(model_path)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc9eeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fadc6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 21ms/step - loss: 0.3531 - accuracy: 0.8661\n",
      "\n",
      "Accuracy: 0.8661360144615173\n",
      "\n",
      "Loss:  0.3530680239200592\n",
      "44/44 [==============================] - 1s 21ms/step\n",
      "\n",
      " Classification report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           L       0.87      0.87      0.87       698\n",
      "           R       0.86      0.87      0.87       684\n",
      "\n",
      "    accuracy                           0.87      1382\n",
      "   macro avg       0.87      0.87      0.87      1382\n",
      "weighted avg       0.87      0.87      0.87      1382\n",
      "\n",
      "\n",
      " Confusion matrix \n",
      "\n",
      " [[604  94]\n",
      " [ 91 593]]\n"
     ]
    }
   ],
   "source": [
    "testLoss, testAcc = model.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy:', testAcc)\n",
    "print('\\nLoss: ', testLoss)\n",
    "\n",
    "yPred = model.predict(x_test)\n",
    "\n",
    "# convert from one hot encode in string\n",
    "if two_class:\n",
    "    yTestClass = []\n",
    "    for label in y_test:\n",
    "        if label==0:\n",
    "            yTestClass.append(\"L\")\n",
    "        elif label==1:\n",
    "            yTestClass.append(\"R\")\n",
    "        else:\n",
    "            print(\"Label not found.\")\n",
    "               \n",
    "    yPredClass = []\n",
    "    for label in yPred:\n",
    "        if label<0.5:\n",
    "            yPredClass.append(\"L\")\n",
    "        elif label>=0.5:\n",
    "            yPredClass.append(\"R\")\n",
    "        else:\n",
    "            print(\"Label not found.\")\n",
    "    \n",
    "    target_names = [\"L\", \"R\"]\n",
    "else:  \n",
    "    yTestClass = np.argmax(y_test, axis=1)\n",
    "    yPredClass = np.argmax(yPred,axis=1)\n",
    "    target_names=[\"B\", \"R\", \"RL\", \"L\", \"F\"]\n",
    "\n",
    "print('\\n Classification report \\n\\n',\n",
    "  classification_report(\n",
    "      yTestClass,\n",
    "      yPredClass,\n",
    "       target_names=target_names\n",
    "  )\n",
    ")\n",
    "\n",
    "print('\\n Confusion matrix \\n\\n',\n",
    "  confusion_matrix(\n",
    "      yTestClass,\n",
    "      yPredClass,\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad370903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
